{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-11T00:31:53.532399Z",
     "iopub.status.busy": "2024-12-11T00:31:53.531280Z",
     "iopub.status.idle": "2024-12-11T00:31:53.537634Z",
     "shell.execute_reply": "2024-12-11T00:31:53.536522Z",
     "shell.execute_reply.started": "2024-12-11T00:31:53.532354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:31:55.740699Z",
     "iopub.status.busy": "2024-12-11T00:31:55.740296Z",
     "iopub.status.idle": "2024-12-11T00:31:55.746056Z",
     "shell.execute_reply": "2024-12-11T00:31:55.744902Z",
     "shell.execute_reply.started": "2024-12-11T00:31:55.740664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configurable parameters\n",
    "IMG_SIZE = (32, 32)  # image resolution\n",
    "NUM_CONV_LAYERS = 5  # convolutional layers\n",
    "BATCH_SIZE = 32  # batch size\n",
    "EPOCHS = 20  # training rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:31:58.417079Z",
     "iopub.status.busy": "2024-12-11T00:31:58.416138Z",
     "iopub.status.idle": "2024-12-11T00:31:58.421301Z",
     "shell.execute_reply": "2024-12-11T00:31:58.420342Z",
     "shell.execute_reply.started": "2024-12-11T00:31:58.417038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data path\n",
    "# train_data_dir = \"/kaggle/input/surface-crack-train/training/\"\n",
    "# test_data_dir = \"/kaggle/input/surface-crack-test/test/\"\n",
    "train_data_dir = 'concrete_crack_images/training'\n",
    "test_data_dir = 'concrete_crack_images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:32:01.500651Z",
     "iopub.status.busy": "2024-12-11T00:32:01.500245Z",
     "iopub.status.idle": "2024-12-11T00:32:01.507999Z",
     "shell.execute_reply": "2024-12-11T00:32:01.506900Z",
     "shell.execute_reply.started": "2024-12-11T00:32:01.500614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training data and partition the training and validation sets\n",
    "def load_and_split_train_data(data_dir, img_size=IMG_SIZE, test_size=0.2):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for label, category in enumerate(['Negative', 'Positive']):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, img_size)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    images = np.array(images) / 255.0  # Data Normalization\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return train_test_split(images, labels, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:32:05.200459Z",
     "iopub.status.busy": "2024-12-11T00:32:05.200035Z",
     "iopub.status.idle": "2024-12-11T00:32:05.207278Z",
     "shell.execute_reply": "2024-12-11T00:32:05.206093Z",
     "shell.execute_reply.started": "2024-12-11T00:32:05.200422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "def load_test_data(data_dir, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    filenames = []\n",
    "\n",
    "    for file in os.listdir(data_dir):\n",
    "        img_path = os.path.join(data_dir, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            filenames.append(file)\n",
    "\n",
    "    images = np.array(images) / 255.0  # Data Normalization\n",
    "    return images, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:32:07.797298Z",
     "iopub.status.busy": "2024-12-11T00:32:07.796583Z",
     "iopub.status.idle": "2024-12-11T00:33:23.962875Z",
     "shell.execute_reply": "2024-12-11T00:33:23.961527Z",
     "shell.execute_reply.started": "2024-12-11T00:32:07.797260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and split training and validation data\n",
    "train_images, val_images, train_labels, val_labels = load_and_split_train_data(train_data_dir)\n",
    "\n",
    "# Load test data\n",
    "test_images, test_filenames = load_test_data(test_data_dir)\n",
    "\n",
    "# Output data statistics\n",
    "print(f\"Training dataset size: {train_images.shape[0]}\")\n",
    "print(f\"Validation dataset size: {val_images.shape[0]}\")\n",
    "print(f\"Testing dataset size: {test_images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:33:46.678212Z",
     "iopub.status.busy": "2024-12-11T00:33:46.677384Z",
     "iopub.status.idle": "2024-12-11T00:33:46.795200Z",
     "shell.execute_reply": "2024-12-11T00:33:46.794185Z",
     "shell.execute_reply.started": "2024-12-11T00:33:46.678172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_conv_layers=NUM_CONV_LAYERS):\n",
    "    model = Sequential()\n",
    "\n",
    "    filters = 32\n",
    "    for i in range(num_conv_layers):\n",
    "        # Adding Convolutional and Pooling Layers\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape if i == 0 else None))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        filters *= 2  # Double the number of filters per layer\n",
    "\n",
    "    # Spreading Characteristics Chart\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #  Fully Connected Layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "cnn_model = create_cnn_model()\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:34:08.688148Z",
     "iopub.status.busy": "2024-12-11T00:34:08.687647Z",
     "iopub.status.idle": "2024-12-11T00:48:07.322479Z",
     "shell.execute_reply": "2024-12-11T00:48:07.321263Z",
     "shell.execute_reply.started": "2024-12-11T00:34:08.688106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# train the model\n",
    "history = cnn_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the computational time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the computational time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:49:31.861470Z",
     "iopub.status.busy": "2024-12-11T00:49:31.861024Z",
     "iopub.status.idle": "2024-12-11T00:49:38.460420Z",
     "shell.execute_reply": "2024-12-11T00:49:38.459324Z",
     "shell.execute_reply.started": "2024-12-11T00:49:31.861432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation set prediction probability\n",
    "val_predictions = cnn_model.predict(val_images).flatten()\n",
    "\n",
    "# Plotting histograms of predicted probability distributions\n",
    "plt.hist(val_predictions, bins=20, color='blue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Validation Set Prediction Probability Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Print basic statistical information about the distribution\n",
    "print(f\"Min: {val_predictions.min()}, Max: {val_predictions.max()}\")\n",
    "print(f\"Mean: {val_predictions.mean()}, Std: {val_predictions.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T00:49:43.570377Z",
     "iopub.status.busy": "2024-12-11T00:49:43.569393Z",
     "iopub.status.idle": "2024-12-11T00:49:44.102673Z",
     "shell.execute_reply": "2024-12-11T00:49:44.101605Z",
     "shell.execute_reply.started": "2024-12-11T00:49:43.570337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting accuracy curves for training and validation\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "for i, value in enumerate(history.history['accuracy']):\n",
    "    plt.text(i, value, f\"{value:.4f}\", ha='center', va='bottom', fontsize=8)\n",
    "for i, value in enumerate(history.history['val_accuracy']):\n",
    "    plt.text(i, value, f\"{value:.4f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss curves for training and validation\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "for i, value in enumerate(history.history['loss']):\n",
    "    plt.text(i, value, f\"{value:.4f}\", ha='center', va='bottom', fontsize=8)\n",
    "for i, value in enumerate(history.history['val_loss']):\n",
    "    plt.text(i, value, f\"{value:.4f}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-11T00:12:54.042817Z",
     "iopub.status.idle": "2024-12-11T00:12:54.043333Z",
     "shell.execute_reply": "2024-12-11T00:12:54.043078Z",
     "shell.execute_reply.started": "2024-12-11T00:12:54.043054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prediction of test data\n",
    "predictions = cnn_model.predict(test_images)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Create DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'image_id': test_filenames,\n",
    "    'predicted_class': predicted_classes\n",
    "})\n",
    "\n",
    "# Save as CSV file\n",
    "output_csv_path = \"predictions.csv\"\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Predictions have been saved to {output_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6275182,
     "sourceId": 10162123,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6275190,
     "sourceId": 10162134,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
